from flask import Flask, render_template, request, jsonify
import ollama

app = Flask(__name__)

# On garde la conversation en m√©moire ici (reset possible)
conversation = [
    {
        "role": "system",
        "content": "Take on the role of a famous personality and mimic them. \
        Your goal is to make us guess who you are through the questions we ask you."
    }
]

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/ask", methods=["POST"])
def ask():
    global conversation
    data = request.get_json()
    user_message = data.get("message", "").strip()

    # Gestion des commandes sp√©ciales
    if user_message.lower() in ["quit", "exit", "stop"]:
        return jsonify({"reply": "üî¥ Conversation ended."})
    elif user_message.lower() == "reset":
        conversation = [
            {
                "role": "system",
                "content": "Take on the role of a famous personality and mimic them. \
                Your goal is to make us guess who you are through the questions we ask you."
            }
        ]
        return jsonify({"reply": "‚ö° Conversation reset."})

    # Ajouter le message de l‚Äôutilisateur
    conversation.append({"role": "user", "content": user_message})

    # Appeler Ollama
    response = ollama.chat(model="gemma3:12b", messages=conversation)

    # R√©cup√©rer la r√©ponse
    ai_reply = response["message"]["content"]

    # Ajouter la r√©ponse √† la conversation
    conversation.append({"role": "assistant", "content": ai_reply})

    return jsonify({"reply": ai_reply})

if __name__ == "__main__":
    app.run(debug=True)
